{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Transformation between Two Cameras \n",
    "1. Stretch Camera ( has a known transformation from base frame)\n",
    "2. Manip/Arm Camera ( unknown from base frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai2thor.robot_client import Controller\n",
    "from ai2thor.robot_grasping import ObjectDetector, GraspPlanner\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# initialize \n",
    "c = Controller(host='172.16.121.205', port=50051, width=1280, height=720, get_depth=False, multi_thread=False, camera_sources=[\"arm\", \"stretch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate stretch camera to face the manipulation workspace\n",
    "c.step(\"RotateHead\")\n",
    "\n",
    "# move arm up and extend such that the aruco markers are visible from both camear\n",
    "c.step({\"action\":[\n",
    "                    #{\"action\": \"MoveArmExtension\", \"args\": {\"move_scalar\": 0.05}},\n",
    "                    {\"action\": \"MoveArmBase\", \"args\": {\"move_scalar\": .05}},\n",
    "\n",
    "]})\n",
    "\n",
    "# get images\n",
    "arm_image = c.last_event.third_party_camera_frames[0]\n",
    "stretch_image = c.last_event.third_party_camera_frames[1]\n",
    "\n",
    "plt.imshow(arm_image)\n",
    "plt.show()\n",
    "plt.imshow(stretch_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Aruco Marker\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "parameters =  cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ARM \n",
    "gray_arm_image = cv2.cvtColor(arm_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_height, image_width = gray_arm_image.shape\n",
    "\n",
    "arm_aruco_corners, arm_aruco_ids, aruco_rejected_image_points = detector.detectMarkers(gray_arm_image)\n",
    "\n",
    "print(arm_aruco_corners)\n",
    "print(arm_aruco_ids)\n",
    "\n",
    "image=arm_image.copy()\n",
    "cv2.aruco.drawDetectedMarkers(image, arm_aruco_corners, arm_aruco_ids) \n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## STRETCH\n",
    "gray_stretch_image = cv2.cvtColor(stretch_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_height, image_width = gray_stretch_image.shape\n",
    "\n",
    "stretch_aruco_corners, stretch_aruco_ids, aruco_rejected_image_points = detector.detectMarkers(gray_stretch_image)\n",
    "\n",
    "print(stretch_aruco_corners)\n",
    "print(stretch_aruco_ids)\n",
    "#print(aruco_rejected_image_points)\n",
    "\n",
    "image=stretch_image.copy()\n",
    "stretch_image_w_aruco = cv2.aruco.drawDetectedMarkers(image, stretch_aruco_corners, stretch_aruco_ids) \n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Camera Intrinsics for pose estimation\n",
    "stretch_cam_intr_file = \"images/camera_intrinsics/camera_intrinsics_102422073668.txt\"\n",
    "arm_cam_intr_file = \"images/camera_intrinsics/camera_intrinsics_234222300666.txt\"\n",
    "\n",
    "import json\n",
    "\n",
    "with open(stretch_cam_intr_file, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    stretch_intr = json.load(file)\n",
    "    # Print the loaded JSON data\n",
    "    print(stretch_intr)\n",
    "\n",
    "with open(arm_cam_intr_file, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    arm_intr = json.load(file)\n",
    "    # Print the loaded JSON data\n",
    "    print(arm_intr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## POSE ESTIMATION\n",
    "def my_estimatePoseSingleMarkers(corners, marker_size, mtx, distortion):\n",
    "    '''\n",
    "    This will estimate the rvec and tvec for each of the marker corners detected by:\n",
    "       corners, ids, rejectedImgPoints = detector.detectMarkers(image)\n",
    "    corners - is an array of detected corners for each detected marker in the image\n",
    "    marker_size - is the size of the detected markers\n",
    "    mtx - is the camera matrix\n",
    "    distortion - is the camera distortion matrix\n",
    "    RETURN list of rvecs, tvecs, and trash (so that it corresponds to the old estimatePoseSingleMarkers())\n",
    "    '''\n",
    "    marker_points = np.array([[-marker_size / 2, marker_size / 2, 0],\n",
    "                              [marker_size / 2, marker_size / 2, 0],\n",
    "                              [marker_size / 2, -marker_size / 2, 0],\n",
    "                              [-marker_size / 2, -marker_size / 2, 0]], dtype=np.float32)\n",
    "    trash = []\n",
    "    rvecs = []\n",
    "    tvecs = []\n",
    "    \n",
    "    for c in corners:\n",
    "        nada, R, t = cv2.solvePnP(marker_points, c, mtx, distortion, False, cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "        rvecs.append(R)\n",
    "        tvecs.append(t)\n",
    "        trash.append(nada)\n",
    "    return rvecs, tvecs, trash\n",
    "\n",
    "\n",
    "## STRETCH\n",
    "length_of_marker_mm = 23.5\n",
    "camera_matrix = np.array([[stretch_intr[\"fx\"], 0, stretch_intr[\"ppx\"]], [0, stretch_intr[\"fy\"], stretch_intr[\"ppy\"]], [0, 0, 1]])\n",
    "distortion_coefficients = np.array(stretch_intr[\"coeffs\"])\n",
    "rvecs, tvecs, unknown_variable = my_estimatePoseSingleMarkers(stretch_aruco_corners,\n",
    "                                                                         length_of_marker_mm,\n",
    "                                                                         camera_matrix,\n",
    "                                                                         distortion_coefficients)\n",
    "\n",
    "stretch_aruco_rotation = rvecs[0]\n",
    "stretch_aruco_position = tvecs[0]/1000.0 # Convert ArUco position estimate to be in meters.\n",
    "print(stretch_aruco_rotation)\n",
    "print(stretch_aruco_position)\n",
    "\n",
    "P_aruco_from_stretch = np.identity(4)\n",
    "P_aruco_from_stretch[:3,:3] = cv2.Rodrigues(stretch_aruco_rotation)[0]\n",
    "P_aruco_from_stretch[0:3,3] = stretch_aruco_position.T\n",
    "print(P_aruco_from_stretch)\n",
    "\n",
    "\n",
    "## ARM\n",
    "length_of_marker_mm = 23.5\n",
    "camera_matrix = np.array([[arm_intr[\"fx\"], 0, arm_intr[\"ppx\"]], [0, arm_intr[\"fy\"], arm_intr[\"ppy\"]], [0, 0, 1]])\n",
    "distortion_coefficients = np.array(arm_intr[\"coeffs\"])\n",
    "rvecs, tvecs, unknown_variable = my_estimatePoseSingleMarkers(arm_aruco_corners,\n",
    "                                                                         length_of_marker_mm,\n",
    "                                                                         camera_matrix,\n",
    "                                                                         distortion_coefficients)\n",
    "\n",
    "arm_aruco_rotation = rvecs[0]\n",
    "arm_aruco_position = tvecs[0]/1000.0 # Convert ArUco position estimate to be in meters.\n",
    "print(arm_aruco_rotation)\n",
    "print(arm_aruco_position)\n",
    "\n",
    "P_aruco_from_arm = np.identity(4)\n",
    "P_aruco_from_arm[:3,:3] = cv2.Rodrigues(arm_aruco_rotation)[0]\n",
    "P_aruco_from_arm[0:3,3] = arm_aruco_position.T\n",
    "print(P_aruco_from_arm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful relationships \n",
    "\n",
    "P_object_from_base = T_camera_from_base @ P_object_from_camera\n",
    "\n",
    "\n",
    "T_stretch_from_arm @ P_aruco_from_stretch   = P_aruco_from_arm\n",
    "\n",
    "T_arm_from_stretch @ P_aruco_from_arm   = P_aruco_from_stretch\n",
    "\n",
    "\n",
    "T_arm_from_base =  T_stretch_from_base @ T_arm_from_stretch\n",
    "\n",
    "==>\n",
    "\n",
    "T_arm_from_stretch =  P_aruco_from_stretch @ (P_aruco_from_arm)_inverse = P_aruco_from_stretch @ P_arm_from_aruco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### INVERSE OF HOMOGENEROUS MATRIX \n",
    "\n",
    "- R_inv => Transpose of R\n",
    "- t_inv => -R_Inv * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_homogeneous_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Compute the inverse of a 4x4 homogeneous transformation matrix.\n",
    "\n",
    "    Args:\n",
    "    matrix (numpy.ndarray): A 4x4 homogeneous transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The inverse of the input matrix.\n",
    "    \"\"\"\n",
    "    if matrix.shape != (4, 4):\n",
    "        raise ValueError(\"Input matrix must be a 4x4 matrix.\")\n",
    "\n",
    "    rotation_matrix = matrix[0:3, 0:3]\n",
    "    translation_vector = matrix[0:3, 3]\n",
    "\n",
    "    inverse_rotation = np.transpose(rotation_matrix)\n",
    "    inverse_translation = -np.dot(inverse_rotation, translation_vector)\n",
    "\n",
    "    inverse_matrix = np.identity(4)\n",
    "    inverse_matrix[0:3, 0:3] = inverse_rotation\n",
    "    inverse_matrix[0:3, 3] = inverse_translation\n",
    "\n",
    "    return inverse_matrix\n",
    "\n",
    "\n",
    "# compute inverse \n",
    "P_arm_from_aruco = inverse_homogeneous_matrix(P_aruco_from_arm)\n",
    "print(P_arm_from_aruco)\n",
    "\n",
    "# compute transformation matrix \n",
    "T_arm_from_stretch =  P_aruco_from_stretch @ P_arm_from_aruco\n",
    "print(T_arm_from_stretch)\n",
    "\n",
    "# confirmation\n",
    "print(\"--------CONFIRMATION--------\")\n",
    "T_stretch_from_arm = inverse_homogeneous_matrix(T_arm_from_stretch)\n",
    "recomputed_P_aruco_from_arm =  T_stretch_from_arm @ P_aruco_from_stretch\n",
    "print(recomputed_P_aruco_from_arm)\n",
    "print(P_aruco_from_arm)\n",
    "\n",
    "\n",
    "\n",
    "# compute transfomration matrix for arm from base \n",
    "print(\"--------T_arm_from_base--------\")\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "r = R.from_quat([0.616, 0.616, -0.346, 0.345]) # camera_color_optical_frame\n",
    "T_stretch_from_base = np.identity(4)\n",
    "T_stretch_from_base[0:3, 0:3] = r.as_matrix()\n",
    "T_stretch_from_base[0:3, 3] = np.array([-0.017, -0.038, 1.294])\n",
    "\n",
    "T_arm_from_base =  T_stretch_from_base @ T_arm_from_stretch\n",
    "print(T_arm_from_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_arm_from_base"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
